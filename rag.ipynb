{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install textgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how long it will take to dry 30 shirts under the sun, we need to consider the drying process and whether it is affected by the number of shirts.\n",
      "\n",
      "1. **Understand the Drying Process**: Drying shirts under the sun is typically a parallel process. Each shirt dries independently of the others, assuming there is enough space and sunlight for all shirts to be exposed equally.\n",
      "\n",
      "2. **Initial Information**: We know that 25 shirts take 1 hour to dry. This implies that each shirt, when exposed to the sun, takes 1 hour to dry.\n",
      "\n",
      "3. **Drying 30 Shirts**: Since drying is a parallel process and each shirt dries independently, adding more shirts does not increase the drying time for each shirt. Therefore, drying 30 shirts will also take 1 hour, provided that all shirts have equal exposure to sunlight and there is no limitation in space or sunlight.\n",
      "\n",
      "4. **Conclusion**: The time it takes to dry 30 shirts is the same as the time it takes to dry 25 shirts, which is 1 hour, assuming all conditions remain constant (e.g., sunlight intensity, space for spreading the shirts).\n",
      "\n",
      "Thus, it will take 1 hour to dry 30 shirts under the sun.\n"
     ]
    }
   ],
   "source": [
    "import textgrad as tg\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify the API key is loaded\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "\n",
    "tg.set_backward_engine(\"gpt-4o\", override=True)\n",
    "\n",
    "# Step 1: Get an initial response from an LLM\n",
    "model = tg.BlackboxLLM(\"gpt-4o\")\n",
    "question_string = (\"If it takes 1 hour to dry 25 shirts under the sun, \"\n",
    "                    \"how long will it take to dry 30 shirts under the sun? \"\n",
    "                    \"Reason step by step.\")\n",
    "\n",
    "question = tg.Variable(question_string, role_description=\"question to the LLM\", requires_grad=False)\n",
    "\n",
    "# Step 2: Get the LLM's response\n",
    "answer = model(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.set_role_description(\"concise and accurate answer to the question\")\n",
    "\n",
    "optimizer = tg.TGD(parameters=[answer], verbose=1)\n",
    "\n",
    "evaluation_instruction = (f\"Here's a question: {question_string}. \"\n",
    "                           \"Evaluate any given answer to this question, \"\n",
    "                           \"be smart, logical, and very critical. \"\n",
    "                           \"Just provide concise feedback.\")\n",
    "\n",
    "loss_fn = tg.TextLoss(evaluation_instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(answer)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

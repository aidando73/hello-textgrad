{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install textgrad dspy faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how long it will take to dry 30 shirts under the sun, we need to consider the drying process and whether it is affected by the number of shirts.\n",
      "\n",
      "1. **Understand the Drying Process**: Drying shirts under the sun is typically a parallel process. Each shirt dries independently of the others, assuming there is enough space and sunlight for all shirts to be exposed equally.\n",
      "\n",
      "2. **Initial Information**: We know that 25 shirts take 1 hour to dry. This implies that each shirt, when exposed to the sun, takes 1 hour to dry.\n",
      "\n",
      "3. **Drying 30 Shirts**: Since drying is a parallel process and each shirt dries independently, adding more shirts does not increase the drying time for each shirt. Therefore, drying 30 shirts will also take 1 hour, provided that all shirts have equal exposure to sunlight and there is no limitation in space or sunlight.\n",
      "\n",
      "4. **Conclusion**: The time it takes to dry 30 shirts is the same as the time it takes to dry 25 shirts, which is 1 hour, assuming all conditions remain constant (e.g., sunlight intensity, space for spreading the shirts).\n",
      "\n",
      "Thus, it will take 1 hour to dry 30 shirts under the sun.\n"
     ]
    }
   ],
   "source": [
    "import textgrad as tg\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify the API key is loaded\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "\n",
    "tg.set_backward_engine(\"gpt-4o\", override=True)\n",
    "\n",
    "# Step 1: Get an initial response from an LLM\n",
    "model = tg.BlackboxLLM(\"gpt-4o\")\n",
    "question_string = (\"If it takes 1 hour to dry 25 shirts under the sun, \"\n",
    "                    \"how long will it take to dry 30 shirts under the sun? \"\n",
    "                    \"Reason step by step.\")\n",
    "\n",
    "question = tg.Variable(question_string, role_description=\"question to the LLM\", requires_grad=False)\n",
    "\n",
    "# Step 2: Get the LLM's response\n",
    "answer = model(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.set_role_description(\"concise and accurate answer to the question\")\n",
    "\n",
    "optimizer = tg.TGD(parameters=[answer], verbose=1)\n",
    "\n",
    "evaluation_instruction = (f\"Here's a question: {question_string}. \"\n",
    "                           \"Evaluate any given answer to this question, \"\n",
    "                           \"be smart, logical, and very critical. \"\n",
    "                           \"Just provide concise feedback.\")\n",
    "\n",
    "loss_fn = tg.TextLoss(evaluation_instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------TextualGradientDescent------------------------\n",
      "To determine how long it will take to dry 30 shirts under the sun, we need to consider the drying process. Drying shirts under the sun is a parallel process, meaning each shirt dries independently, assuming there is sufficient space and sunlight for all shirts. Given that 25 shirts take 1 hour to dry, each shirt takes 1 hour to dry. Therefore, drying 30 shirts will also take 1 hour, assuming equal exposure and no space limitations. The drying time is independent of the number of shirts as long as conditions remain constant.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable(value=To determine how long it will take to dry 30 shirts under the sun, we need to consider the drying process. Drying shirts under the sun is a parallel process, meaning each shirt dries independently, assuming there is sufficient space and sunlight for all shirts. Given that 25 shirts take 1 hour to dry, each shirt takes 1 hour to dry. Therefore, drying 30 shirts will also take 1 hour, assuming equal exposure and no space limitations. The drying time is independent of the number of shirts as long as conditions remain constant., role=concise and accurate answer to the question, grads={Variable(value=To improve the concise and accurate answer to the question, consider the following feedback:\n",
       "\n",
       "1. **Clarify Assumptions**: While the answer correctly identifies that the drying process is parallel, it could benefit from explicitly stating the assumption that there is sufficient space and sunlight for all shirts. This would preemptively address any potential concerns about limitations in drying conditions.\n",
       "\n",
       "2. **Simplify Language**: The explanation could be made more concise by reducing redundancy. For instance, the phrase \"provided that all shirts have equal exposure to sunlight and there is no limitation in space or sunlight\" could be streamlined to \"assuming equal exposure and no space limitations.\"\n",
       "\n",
       "3. **Address Potential Variables**: While the answer assumes constant conditions, it could briefly mention potential variables that might affect drying time, such as changes in weather or obstructions to sunlight, to demonstrate a comprehensive understanding of the drying process.\n",
       "\n",
       "4. **Use of Examples**: Incorporating a brief example or analogy could help illustrate the concept of parallel drying more clearly, making the explanation more relatable and easier to understand.\n",
       "\n",
       "5. **Focus on Key Points**: The answer could emphasize the key point that the drying time is independent of the number of shirts, as long as conditions remain constant, to reinforce the main conclusion.\n",
       "\n",
       "By addressing these points, the answer could become more concise, clear, and robust, thereby improving the objective function of providing a concise and accurate answer., role=feedback to concise and accurate answer to the question, grads=set())})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(answer)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable(value=In the context of Linux, \"high memory\" and \"low memory\" refer to different regions of the system's physical memory, particularly on 32-bit systems. This distinction arises from the way memory is managed and accessed by the operating system and hardware.\n",
       "\n",
       "### Low Memory\n",
       "\n",
       "- **Definition**: Low memory is the portion of physical memory that is directly accessible by the kernel without any special handling. On 32-bit systems, this typically includes the first 896 MB of RAM.\n",
       "- **Address Space**: It is mapped directly into the kernel's address space, allowing the kernel to access it easily and efficiently.\n",
       "- **Usage**: Low memory is used for kernel data structures, buffers, and other critical components that require fast and direct access by the kernel.\n",
       "- **Limitations**: The size of low memory is limited by the architecture and the kernel's address space layout, which can be a constraint on systems with large amounts of RAM.\n",
       "\n",
       "### High Memory\n",
       "\n",
       "- **Definition**: High memory refers to the portion of physical memory that is not directly mapped into the kernel's address space. On 32-bit systems, this is typically any memory above the 896 MB threshold.\n",
       "- **Address Space**: High memory requires special handling to be accessed by the kernel. It is not directly accessible and must be mapped into the kernel's address space temporarily when needed.\n",
       "- **Usage**: High memory is used for user-space applications and data that do not require constant access by the kernel. It is managed using techniques like paging to make it accessible when necessary.\n",
       "- **Handling**: The kernel uses mechanisms like page tables to map high memory into its address space as needed, which can introduce some overhead compared to low memory access.\n",
       "\n",
       "### 64-bit Systems\n",
       "\n",
       "On 64-bit systems, the distinction between high and low memory is less relevant because the address space is large enough to map all of physical memory directly into the kernel's address space. This eliminates the need for special handling of high memory, simplifying memory management.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "The distinction between high and low memory is primarily a concern for 32-bit systems with large amounts of RAM. It reflects the limitations of the 32-bit address space and the need for efficient memory management techniques to handle more memory than can be directly addressed. On modern 64-bit systems, these concerns are largely mitigated by the expanded address space., role=response from the language model, grads=set())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_string = (\"what are high memory and low memory in linux?\")\n",
    "\n",
    "question = tg.Variable(question_string, role_description=\"question to the LLM\", requires_grad=False)\n",
    "\n",
    "# Step 2: Get the LLM's response\n",
    "answer = model(question)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'why are my text messages coming up as maybe?',\n",
       " 'response': 'This is part of the Proactivity features new with iOS 9: It looks at info in emails to see if anyone with this number sent you an email and if it finds the phone number associated with a contact from your email, it will show you \"Maybe\". \\n\\nHowever, it has been suggested there is a bug in iOS 11.2 that can result in \"Maybe\" being displayed even when \"Find Contacts in Other Apps\" is disabled.',\n",
       " 'gold_doc_ids': [3956, 3957, 8034]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"ragqa_arena_tech_examples.jsonl\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 300, 500)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.Random(0).shuffle(data)\n",
    "trainset, devset, testset = data[:200], data[200:500], data[500:1000]\n",
    "\n",
    "len(trainset), len(devset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just importing dspy for the metric only\n",
    "from dspy.evaluate import SemanticF1\n",
    "import dspy\n",
    "\n",
    "# Instantiate the metric.\n",
    "metric = SemanticF1(decompositional=True)\n",
    "model = tg.BlackboxLLM(\"gpt-4o\")\n",
    "\n",
    "# Produce a prediction from our `cot` module, using the `example` above as input.\n",
    "example = data[2]\n",
    "question = tg.Variable(example[\"question\"], role_description=\"question to the LLM\", requires_grad=False)\n",
    "pred = model(question)\n",
    "\n",
    "# Compute the metric score for the prediction.\n",
    "lm = dspy.LM('openai/gpt-4o-mini')\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "def evaluate_single(the_model, the_example):\n",
    "    the_example = dspy.Example(\n",
    "        question=the_example[\"question\"],\n",
    "        response=the_example[\"response\"]\n",
    "    )\n",
    "    question = tg.Variable(the_example[\"question\"], role_description=\"question to the LLM\", requires_grad=False)\n",
    "    pred = dspy.Prediction(\n",
    "        response=the_model(question)\n",
    "    )\n",
    "    score = metric(the_example, pred)\n",
    "    # print(\"Question:\\n\", example.question)\n",
    "    # print(\"\\n\\nGround truth:\\n\", example.response)\n",
    "    # print(\"\\n\\nPrediction:\\n\", pred.response)\n",
    "    # print(\"\\n\\nSemantic F1 score:\", score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Clear instances\n",
    "tqdm._instances.clear()\n",
    "\n",
    "# Reset monitor thread\n",
    "if hasattr(tqdm, 'monitor'):\n",
    "    tqdm.monitor.exit()\n",
    "    tqdm.monitor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# def evaluate(the_model):\n",
    "#     total_score = 0\n",
    "#     top_score = 0\n",
    "#     pbar = tqdm(devset)\n",
    "#     for example in pbar:\n",
    "#         score = evaluate_single(the_model, example)\n",
    "#         total_score += score\n",
    "#         top_score += 1\n",
    "#         pbar.set_description(f\"Evaluating (score: {total_score:.1f}/{top_score}, {total_score/max(1, top_score):.2%})\")\n",
    "#     return total_score / top_score\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(the_model):\n",
    "    total_score = 0\n",
    "    pbar = tqdm(total=len(devset), position=0, leave=True)\n",
    "\n",
    "    # Use ThreadPoolExecutor since the work is I/O bound (API calls)\n",
    "    with ThreadPoolExecutor(max_workers=24) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_example = {\n",
    "            executor.submit(evaluate_single, the_model, example): example \n",
    "            for example in devset\n",
    "        }\n",
    "        \n",
    "        # Process completed tasks as they finish\n",
    "        for future in as_completed(future_to_example):\n",
    "            score = future.result()\n",
    "            total_score += score\n",
    "            pbar.update(1)\n",
    "            pbar.set_description(f\"Evaluating (score: {total_score:.1f}/{pbar.n}, {total_score/max(1, pbar.n):.2%})\")\n",
    "    \n",
    "    pbar.close()\n",
    "    return total_score / len(devset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (score: 39.6/82, 48.25%):  27%|██▋       | 82/301 [01:50<04:54,  1.35s/it] \n",
      "Evaluating (score: 134.0/300, 44.66%): 100%|██████████| 300/300 [02:03<00:00,  2.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.446588789809674"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a 32-byte FAISS index with 337 partitions, based on 28436 x 512-dim embeddings\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "max_characters = 6000  # for truncating >99th percentile of documents\n",
    "topk_docs_to_retrieve = 5  # number of documents to retrieve per search query\n",
    "\n",
    "with open(\"ragqa_arena_tech_corpus.jsonl\") as f:\n",
    "    corpus = [json.loads(line)['text'][:max_characters] for line in f]\n",
    "\n",
    "embedder = dspy.Embedder('openai/text-embedding-3-small', dimensions=512)\n",
    "search = dspy.retrievers.Embeddings(embedder=embedder, corpus=corpus, k=topk_docs_to_retrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As far as I remember, High Memory is used for application space and Low Memory for the kernel. Advantage is that (user-space) applications cant access kernel-space memory.\n",
      "This is relevant to the Linux kernel; Im not sure how any Unix kernel handles this. The High Memory is the segment of memory that user-space programs can address. It cannot touch Low Memory. Low Memory is the segment of memory that the Linux kernel can address directly. If the kernel must access High Memory, it has to map it into its own address space first. There was a patch introduced recently that lets you control where the segment is. The tradeoff is that you can take addressable memory away from user space so that the kernel can have more memory that it does not have to map before using. Additional resources: http://tldp.org/HOWTO/KernelAnalysis-HOWTO-7.html http://linux-mm.org/HighMemory\n",
      "HIGHMEM is a range of kernels memory space, but it is NOT memory you access but its a place where you put what you want to access. A typical 32bit Linux virtual memory map is like: 0x00000000-0xbfffffff: user process (3GB) 0xc0000000-0xffffffff: kernel space (1GB) (CPU-specific vector and whatsoever are ignored here). Linux splits the 1GB kernel space into 2 pieces, LOWMEM and HIGHMEM. The split varies from installation to installation. If an installation chooses, say, 512MB-512MB for LOW and HIGH mems, the 512MB LOWMEM (0xc0000000-0xdfffffff) is statically mapped at the kernel boot time; usually the first so many bytes of the physical memory is used for this so that virtual and physical addresses in this range have a constant offset of, say, 0xc0000000. On the other hand, the latter 512MB (HIGHMEM) has no static mapping (although you could leave pages semi-permanently mapped there, but you must do so explicitly in your driver code). Instead, pages are temporarily mapped and unmapped here so that virtual and physical addresses in this range have no consistent mapping. Typical uses of HIGHMEM include single-time data buffers.\n",
      "The first reference to turn to is Linux Device Drivers (available both online and in book form), particularly chapter 15 which has a section on the topic. In an ideal world, every system component would be able to map all the memory it ever needs to access. And this is the case for processes on Linux and most operating systems: a 32-bit process can only access a little less than 2^32 bytes of virtual memory (in fact about 3GB on a typical Linux 32-bit architecture). It gets difficult for the kernel, which needs to be able to map the full memory of the process whose system call its executing, plus the whole physical memory, plus any other memory-mapped hardware device. So when a 32-bit kernel needs to map more than 4GB of memory, it must be compiled with high memory support. High memory is memory which is not permanently mapped in the kernels address space. (Low memory is the opposite: it is always mapped, so you can access it in the kernel simply by dereferencing a pointer.) When you access high memory from kernel code, you need to call kmap first, to obtain a pointer from a page data structure (struct page). Calling kmap works whether the page is in high or low memory. There is also kmap_atomic which has added constraints but is more efficient on multiprocessor machines because it uses finer-grained locking. The pointer obtained through kmap is a resource: it uses up address space. Once youve finished with it, you must call kunmap (or kunmap_atomic) to free that resource; then the pointer is no longer valid, and the contents of the page cant be accessed until you call kmap again.\n",
      "/proc/meminfo will tell you how free works, but /proc/kcore can tell you what the kernel uses. From the same page: /proc/kcore This file represents the physical memory of the system and is stored in the ELF core file format. With this pseudo-file, and an unstripped kernel (/usr/src/linux/vmlinux) binary, GDB can be used to examine the current state of any kernel data structures. The total length of the file is the size of physical memory (RAM) plus 4KB. /proc/meminfo This file reports statistics about memory usage on the system. It is used by free(1) to report the amount of free and used memory (both physical and swap) on the system as well as the shared memory and buffers used by the kernel. Each line of the file consists of a parameter name, followed by a colon, the value of the parameter, and an option unit of measurement (e.g., kB). The list below describes the parameter names and the format specifier required to read the field value. Except as noted below, all of the fields have been present since at least Linux 2.6.0. Some fileds are displayed only if the kernel was configured with various options; those dependencies are noted in the list. MemTotal %lu Total usable RAM (i.e., physical RAM minus a few reserved bits and the kernel binary code). MemFree %lu The sum of LowFree+HighFree. Buffers %lu Relatively temporary storage for raw disk blocks that shouldnt get tremendously large (20MB or so). Cached %lu In-memory cache for files read from the disk (the page cache). Doesnt include SwapCached. SwapCached %lu Memory that once was swapped out, is swapped back in but still also is in the swap file. (If memory pressure is high, these pages dont need to be swapped out again because they are already in the swap file. This saves I/O.) Active %lu Memory that has been used more recently and usually not reclaimed unless absolutely necessary. Inactive %lu Memory which has been less recently used. It is more eligible to be reclaimed for other purposes. Active(anon) %lu (since Linux 2.6.28) [To be documented.] Inactive(anon) %lu (since Linux 2.6.28) [To be documented.] Active(file) %lu (since Linux 2.6.28) [To be documented.] Inactive(file) %lu (since Linux 2.6.28) [To be documented.] Unevictable %lu (since Linux 2.6.28) (From Linux 2.6.28 to 2.6.30, CONFIG_UNEVICTABLE_LRU was required.) [To be documented.] Mlocked %lu (since Linux 2.6.28) (From Linux 2.6.28 to 2.6.30, CONFIG_UNEVICTABLE_LRU was required.) [To be documented.] HighTotal %lu (Starting with Linux 2.6.19, CONFIG_HIGHMEM is required.) Total amount of highmem. Highmem is all memory above ~860MB of physical memory. Highmem areas are for use by user-space programs, or for the page cache. The kernel must use tricks to access this memory, making it slower to access than lowmem. HighFree %lu (Starting with Linux 2.6.19, CONFIG_HIGHMEM is required.) Amount of free highmem. LowTotal %lu (Starting with Linux 2.6.19, CONFIG_HIGHMEM is required.) Total amount of lowmem. Lowmem is memory which can be used for everything that highmem can be used for, but it is also available for the kernels use for its own data structures. Among many other things, it is where everything from Slab is allocated. Bad things happen when youre out of lowmem. LowFree %lu (Starting with Linux 2.6.19, CONFIG_HIGHMEM is required.) Amount of free lowmem. MmapCopy %lu (since Linux 2.6.29) (CONFIG_MMU is required.) [To be documented.] SwapTotal %lu Total amount of swap space available. SwapFree %lu Amount of swap space that is currently unused. Dirty %lu Memory which is waiting to get written back to the disk. Writeback %lu Memory which is actively being written back to the disk. AnonPages %lu (since Linux 2.6.18) Non-file backed pages mapped into user-space page tables. Mapped %lu Files which have been mmaped, such as libraries. Shmem %lu (since Linux 2.6.32) [To be documented.] Slab %lu In-kernel data structures cache. SReclaimable %lu (since Linux 2.6.19) Part of Slab, that might be reclaimed, such as caches. SUnreclaim %lu (since Linux 2.6.19) Part of Slab, that cannot be reclaimed on memory pressure. KernelStack %lu (since Linux 2.6.32) Amount of memory allocated to kernel stacks. PageTables %lu (since Linux 2.6.18) Amount of memory dedicated to the lowest level of page tables. Quicklists %lu (since Linux 2.6.27) (CONFIG_QUICKLIST is required.) [To be documented.] NFS_Unstable %lu (since Linux 2.6.18) NFS pages sent to the server, but not yet committed to stable storage. Bounce %lu (since Linux 2.6.18) Memory used for block device bounce buffers. WritebackTmp %lu (since Linux 2.6.26) Memory used by FUSE for temporary writeback buffers. CommitLimit %lu (since Linux 2.6.10) Based on the overcommit ratio (vm.overcommit_ratio), this is the total amount of memory currently available to be allocated on the system. This limit is adhered to only if strict overcommit accounting is enabled (mode 2 in /proc/sys/vm/overcommit_ratio). The CommitLimit is calculated using the following formula: CommitLimit = ([total RAM pages] - [total huge TLB pages]) * overcommit_ratio / 100 + [total swap pages] For example, on a system with 1GB of physical RAM and 7GB of swap with a overcommit_ratio of 30, this formula yields a CommitLimit of 7.3GB. For more details, see the memory overcommit documentation in the kernel source file Documentation/vm/overcommit-accounting. Committed_AS %lu The amount of memory presently allocated on the system. The committed memory is a sum of all of the memory which has been allocated by processes, even if it has not been used by them as of yet. A process which allocates 1GB of memory (using malloc(3) or similar), but touches only 300MB of that memory will show up as using only 300MB of memory even if it has the address space allocated for the entire 1GB. This 1GB is memory which has been committed to by the VM and can be used at any time by the allocating application. With strict overcommit enabled on the system (mode 2 /proc/sys/vm/overcommit_memory), allocations w\n",
      "what are high memory and low memory in linux?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable(value=In the context of the Linux kernel, particularly on 32-bit systems, memory is divided into two main regions: **Low Memory** and **High Memory**. This division is primarily due to the limitations of 32-bit addressing and the need for the kernel to efficiently manage memory.\n",
       "\n",
       "### Low Memory\n",
       "- **Definition**: Low Memory is the portion of memory that the kernel can directly address and access without any additional mapping. It is always mapped into the kernel's address space.\n",
       "- **Characteristics**:\n",
       "  - It is used for kernel data structures, buffers, and other critical components that require fast and direct access.\n",
       "  - The size of Low Memory is limited by the architecture and the configuration of the kernel. On a typical 32-bit Linux system, the kernel address space is 1GB, and Low Memory is a part of this space.\n",
       "  - Low Memory is crucial for the kernel's operations, and running out of Low Memory can lead to system instability.\n",
       "\n",
       "### High Memory\n",
       "- **Definition**: High Memory is the portion of memory that is not permanently mapped into the kernel's address space. It is used primarily for user-space applications and data that do not require constant access by the kernel.\n",
       "- **Characteristics**:\n",
       "  - High Memory is used to extend the available memory beyond what can be directly addressed by the kernel.\n",
       "  - To access High Memory, the kernel must temporarily map it into its address space using functions like `kmap` and `kunmap`.\n",
       "  - This mapping and unmapping process introduces some overhead, making access to High Memory slower compared to Low Memory.\n",
       "\n",
       "### Why the Division?\n",
       "- **Addressing Limitations**: On 32-bit systems, the total addressable space is 4GB. The kernel needs to manage both its own operations and user-space processes within this limit.\n",
       "- **Efficiency**: By keeping frequently accessed data in Low Memory, the kernel can operate more efficiently without the need for constant mapping and unmapping.\n",
       "- **Security and Stability**: Separating user-space and kernel-space memory helps in maintaining system security and stability, as user-space applications cannot directly access kernel memory.\n",
       "\n",
       "### Modern Systems\n",
       "- On 64-bit systems, the distinction between High and Low Memory is less relevant because the addressable space is vastly larger, allowing the kernel to map much more memory directly.\n",
       "- However, the concepts are still important for understanding how memory management evolved and for systems that still operate on 32-bit architectures.\n",
       "\n",
       "In summary, Low Memory is directly accessible by the kernel and used for critical operations, while High Memory extends the available memory for user-space applications, requiring additional steps for the kernel to access it., role=response from the language model, grads=set())"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RAG():\n",
    "    def __init__(self, model, search):\n",
    "        self.model = model\n",
    "        self.search = search\n",
    "\n",
    "    def __call__(self, question):\n",
    "        docs = self.search(question)\n",
    "        context = \"\\n\".join(docs.passages)\n",
    "        question = tg.Variable(context + \"\\n\" + question, role_description=\"question to the LLM\", requires_grad=False)\n",
    "        print(question)\n",
    "        return self.model(question)\n",
    "\n",
    "rag = RAG(model, search)\n",
    "\n",
    "rag(\"what are high memory and low memory in linux?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aidando73/hello-textgrad/blob/main/examples/notebooks/Tutorial-Prompt-Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fecb2fb5-b87f-4428-8175-e3a46fe77371",
      "metadata": {
        "id": "fecb2fb5-b87f-4428-8175-e3a46fe77371"
      },
      "source": [
        "## Tutorial: Optimizing a Prompt\n",
        "\n",
        "![TextGrad](https://github.com/vinid/data/blob/master/logo_full.png?raw=true)\n",
        "\n",
        "An autograd engine -- for textual gradients!\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zou-group/TextGrad/blob/main/examples/notebooks/Prompt-Optimization.ipynb)\n",
        "[![GitHub license](https://img.shields.io/badge/License-MIT-blue.svg)](https://lbesson.mit-license.org/)\n",
        "[![Arxiv](https://img.shields.io/badge/arXiv-2406.07496-B31B1B.svg)](https://arxiv.org/abs/2406.07496)\n",
        "[![Documentation Status](https://readthedocs.org/projects/textgrad/badge/?version=latest)](https://textgrad.readthedocs.io/en/latest/?badge=latest)\n",
        "[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/textgrad)](https://pypi.org/project/textgrad/)\n",
        "[![PyPI](https://img.shields.io/pypi/v/textgrad)](https://pypi.org/project/textgrad/)\n",
        "\n",
        "**Objectives:**\n",
        "\n",
        "* In this tutorial, we will run prompt optimization.\n",
        "\n",
        "**Requirements:**\n",
        "\n",
        "* You need to have an OpenAI API key to run this tutorial. This should be set as an environment variable as OPENAI_API_KEY.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7add4547-4278-411b-a827-79be521851f1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-11T19:30:34.029594610Z",
          "start_time": "2024-06-11T19:30:34.024175489Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7add4547-4278-411b-a827-79be521851f1",
        "outputId": "10601b53-4c5d-424c-e5fe-38d2f3f8537e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textgrad\n",
            "  Downloading textgrad-0.1.6.tar.gz (71 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/72.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/72.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai>=1.23.6 in /usr/local/lib/python3.11/dist-packages (from textgrad) (1.61.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from textgrad) (9.0.0)\n",
            "Collecting python-dotenv>=1.0.0 (from textgrad)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from textgrad) (2.2.2)\n",
            "Requirement already satisfied: platformdirs>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from textgrad) (4.3.6)\n",
            "Collecting datasets>=2.14.6 (from textgrad)\n",
            "  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting diskcache>=5.6.3 (from textgrad)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: graphviz>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from textgrad) (0.20.3)\n",
            "Requirement already satisfied: gdown>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from textgrad) (5.2.0)\n",
            "Collecting litellm>=1.49.5 (from textgrad)\n",
            "  Downloading litellm-1.63.8-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from textgrad) (11.1.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from textgrad) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->textgrad) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->textgrad) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->textgrad) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->textgrad)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->textgrad) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->textgrad) (4.67.1)\n",
            "Collecting xxhash (from datasets>=2.14.6->textgrad)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.6->textgrad)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.14.6->textgrad) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->textgrad) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->textgrad) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->textgrad) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->textgrad) (6.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=5.2.0->textgrad) (4.13.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm>=1.49.5->textgrad) (8.1.8)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.49.5->textgrad) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.49.5->textgrad) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.49.5->textgrad) (4.23.0)\n",
            "Collecting openai>=1.23.6 (from textgrad)\n",
            "  Downloading openai-1.66.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.49.5->textgrad) (2.10.6)\n",
            "Collecting tiktoken>=0.7.0 (from litellm>=1.49.5->textgrad)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm>=1.49.5->textgrad) (0.21.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->textgrad) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->textgrad) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->textgrad) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->textgrad) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->textgrad) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.23.6->textgrad) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.23.6->textgrad) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.23.6->textgrad) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.23.6->textgrad) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->textgrad) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->textgrad) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->textgrad) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.18.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.49.5->textgrad) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.49.5->textgrad) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.49.5->textgrad) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.49.5->textgrad) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.49.5->textgrad) (0.23.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm>=1.49.5->textgrad) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm>=1.49.5->textgrad) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->textgrad) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad) (2.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm>=1.49.5->textgrad) (2024.11.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=5.2.0->textgrad) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=5.2.0->textgrad) (1.7.1)\n",
            "Downloading datasets-3.4.0-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.63.8-py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.66.3-py3-none-any.whl (567 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.4/567.4 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: textgrad\n",
            "  Building wheel for textgrad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textgrad: filename=textgrad-0.1.6-py3-none-any.whl size=79507 sha256=cdfb975bf134302c04f9ded68460b670b2081071666ee333063a7a089869d63f\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/d4/52/3c2739ca15e94cca0fb949438e216b6841d49e14be22b57554\n",
            "Successfully built textgrad\n",
            "Installing collected packages: xxhash, python-dotenv, diskcache, dill, tiktoken, multiprocess, openai, litellm, datasets, textgrad\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "Successfully installed datasets-3.4.0 dill-0.3.8 diskcache-5.6.3 litellm-1.63.8 multiprocess-0.70.16 openai-1.66.3 python-dotenv-1.0.1 textgrad-0.1.6 tiktoken-0.9.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install textgrad # you might need to restart the notebook after installing textgrad\n",
        "\n",
        "import argparse\n",
        "import concurrent\n",
        "from dotenv import load_dotenv\n",
        "from tqdm import tqdm\n",
        "import textgrad as tg\n",
        "from textgrad.tasks import load_task\n",
        "import numpy as np\n",
        "import random\n",
        "load_dotenv(override=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a459a37-7446-4c4a-a7e0-38182b5dbd3e",
      "metadata": {
        "id": "9a459a37-7446-4c4a-a7e0-38182b5dbd3e"
      },
      "source": [
        "Let's first define some support functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1ccc3b21bf9ddc48",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-11T19:30:42.098338405Z",
          "start_time": "2024-06-11T19:30:42.093473103Z"
        },
        "id": "1ccc3b21bf9ddc48"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "from google.colab import userdata\n",
        "from os import environ\n",
        "environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "649e06aef34d0990",
      "metadata": {
        "id": "649e06aef34d0990"
      },
      "outputs": [],
      "source": [
        "def eval_sample(item, eval_fn, model):\n",
        "    \"\"\"\n",
        "    This function allows us to evaluate if an answer to a question in the prompt is a good answer.\n",
        "\n",
        "    \"\"\"\n",
        "    x, y = item\n",
        "    x = tg.Variable(x, requires_grad=False, role_description=\"query to the language model\")\n",
        "    y = tg.Variable(y, requires_grad=False, role_description=\"correct answer for the query\")\n",
        "    response = model(x)\n",
        "    try:\n",
        "        eval_output_variable = eval_fn(inputs=dict(prediction=response, ground_truth_answer=y))\n",
        "        return int(eval_output_variable.value)\n",
        "    except:\n",
        "        eval_output_variable = eval_fn([x, y, response])\n",
        "        eval_output_parsed = eval_fn.parse_output(eval_output_variable)\n",
        "        return int(eval_output_parsed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9559a31e07e54d7f",
      "metadata": {
        "id": "9559a31e07e54d7f"
      },
      "outputs": [],
      "source": [
        "def eval_dataset(test_set, eval_fn, model, max_samples: int=None):\n",
        "    if max_samples is None:\n",
        "        max_samples = len(test_set)\n",
        "    accuracy_list = []\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        futures = []\n",
        "        for _, sample in enumerate(test_set):\n",
        "\n",
        "            future = executor.submit(eval_sample, sample, eval_fn, model)\n",
        "            futures.append(future)\n",
        "            if len(futures) >= max_samples:\n",
        "                break\n",
        "        tqdm_loader = tqdm(concurrent.futures.as_completed(futures), total=len(futures), position=0)\n",
        "        for future in tqdm_loader:\n",
        "            acc_item = future.result()\n",
        "            accuracy_list.append(acc_item)\n",
        "            tqdm_loader.set_description(f\"Accuracy: {np.mean(accuracy_list)}\")\n",
        "    return accuracy_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4ea732b7edf34eb9",
      "metadata": {
        "id": "4ea732b7edf34eb9"
      },
      "outputs": [],
      "source": [
        "def run_validation_revert(system_prompt: tg.Variable, results, model, eval_fn, val_set):\n",
        "    val_performance = np.mean(eval_dataset(val_set, eval_fn, model))\n",
        "    previous_performance = np.mean(results[\"validation_acc\"][-1])\n",
        "    print(\"val_performance: \", val_performance)\n",
        "    print(\"previous_performance: \", previous_performance)\n",
        "    previous_prompt = results[\"prompt\"][-1]\n",
        "\n",
        "    if val_performance < previous_performance:\n",
        "        print(f\"rejected prompt: {system_prompt.value}\")\n",
        "        system_prompt.set_value(previous_prompt)\n",
        "        val_performance = previous_performance\n",
        "\n",
        "    results[\"validation_acc\"].append(val_performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e69f8431-661c-42f8-b7fc-efccea588a03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e69f8431-661c-42f8-b7fc-efccea588a03",
        "outputId": "aa25fbcf-3aaf-4531-def2-f5248f95a0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Val/Test Set Lengths:  50 100 100\n"
          ]
        }
      ],
      "source": [
        "set_seed(12)\n",
        "llm_api_eval = tg.get_engine(engine_name=\"gpt-4o\")\n",
        "llm_api_test = tg.get_engine(engine_name=\"gpt-3.5-turbo-0125\")\n",
        "tg.set_backward_engine(llm_api_eval, override=True)\n",
        "\n",
        "# Load the data and the evaluation function\n",
        "train_set, val_set, test_set, eval_fn = load_task(\"BBH_object_counting\", evaluation_api=llm_api_eval)\n",
        "print(\"Train/Val/Test Set Lengths: \", len(train_set), len(val_set), len(test_set))\n",
        "STARTING_SYSTEM_PROMPT = train_set.get_task_description()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f40b576c-4ba0-4e6e-b3ed-81eb44524676",
      "metadata": {
        "id": "f40b576c-4ba0-4e6e-b3ed-81eb44524676"
      },
      "source": [
        "This is the system prompt we are going to start from:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3ed3261-6f9d-4906-8c4b-a3ad570f5950",
      "metadata": {
        "id": "d3ed3261-6f9d-4906-8c4b-a3ad570f5950"
      },
      "outputs": [],
      "source": [
        "print(STARTING_SYSTEM_PROMPT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7544127-38e0-4c74-8632-003efcc645ee",
      "metadata": {
        "id": "f7544127-38e0-4c74-8632-003efcc645ee",
        "outputId": "484da90b-d245-49d0-9612-48ea91fa0118"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7142857142857143: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1438.83it/s]\n",
            "Accuracy: 0.6867469879518072: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 1318.42it/s]\n"
          ]
        }
      ],
      "source": [
        "train_loader = tg.tasks.DataLoader(train_set, batch_size=3, shuffle=True)\n",
        "\n",
        "\n",
        "# Testing the 0-shot performance of the evaluation engine\n",
        "system_prompt = tg.Variable(STARTING_SYSTEM_PROMPT,\n",
        "                            requires_grad=True,\n",
        "                            role_description=\"system prompt to the language model\")\n",
        "model_evaluation = tg.BlackboxLLM(llm_api_eval, system_prompt)\n",
        "\n",
        "system_prompt = tg.Variable(STARTING_SYSTEM_PROMPT,\n",
        "                            requires_grad=True,\n",
        "                            role_description=\"structured system prompt to a somewhat capable language model that specifies the behavior and strategies for the QA task\")\n",
        "model = tg.BlackboxLLM(llm_api_test, system_prompt)\n",
        "\n",
        "optimizer = tg.TextualGradientDescent(engine=llm_api_eval, parameters=[system_prompt])\n",
        "\n",
        "results = {\"test_acc\": [], \"prompt\": [], \"validation_acc\": []}\n",
        "results[\"test_acc\"].append(eval_dataset(test_set, eval_fn, model))\n",
        "results[\"validation_acc\"].append(eval_dataset(val_set, eval_fn, model))\n",
        "results[\"prompt\"].append(system_prompt.get_value())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3807736-1d81-4349-95db-257c20110d1a",
      "metadata": {
        "id": "b3807736-1d81-4349-95db-257c20110d1a",
        "outputId": "edd5fdaf-5d9b-4a51-a1b1-61d69b8d4079"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5542168674698795: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:21<00:00,  3.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.5542168674698795\n",
            "previous_performance:  0.6867469879518072\n",
            "rejected prompt: You will answer a reasoning question. Provide the final numerical answer directly. Your response should be a single numerical value. Do not include any explanation or additional text, only the numerical answer.\n",
            "sys prompt:  You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7142857142857143: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1201.24it/s]\n",
            "Accuracy: 0.8313253012048193: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:43<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.8313253012048193\n",
            "previous_performance:  0.6867469879518072\n",
            "sys prompt:  You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of the question and focus on counting the items accurately. List each item you count and then verify the total number. Avoid adding any extra information or context that is not directly related to the total count. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8214285714285714: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:43<00:00,  1.94it/s]\n",
            "Accuracy: 0.5542168674698795: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:46<00:00,  1.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.5542168674698795\n",
            "previous_performance:  0.8313253012048193\n",
            "rejected prompt: You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of the question and focus on counting the items accurately. \n",
            "\n",
            "1. Restate the question to ensure clarity.\n",
            "2. List each item you count on a new line using bullet points for clarity. If there are multiple items of the same type, list them together and indicate the quantity.\n",
            "3. Ensure the numbering and items in the list are consistent and free from typographical errors.\n",
            "4. After listing all items, count the total number of items and provide the final count in the specified format.\n",
            "5. Verify the total number by cross-checking with the list.\n",
            "6. If there are potential errors or ambiguities in the list, acknowledge them and request additional details if necessary.\n",
            "\n",
            "The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n",
            "sys prompt:  You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of the question and focus on counting the items accurately. List each item you count and then verify the total number. Avoid adding any extra information or context that is not directly related to the total count. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8214285714285714: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1638.96it/s]\n",
            "Accuracy: 0.6867469879518072: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:18<00:00,  4.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.6867469879518072\n",
            "previous_performance:  0.8313253012048193\n",
            "rejected prompt: You will answer a reasoning question that involves counting items in a list. Directly compute the total number of items and provide the final count. Ensure you understand the context of the question and focus on counting the items accurately. Avoid adding any extra information or context that is not directly related to the total count. Ensure your response follows the format 'Answer: $VALUE' with no additional text. If the input contains unexpected characters or is malformed, correct the input and provide a coherent response. Ensure the final line contains only the answer in the required format.\n",
            "sys prompt:  You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of the question and focus on counting the items accurately. List each item you count and then verify the total number. Avoid adding any extra information or context that is not directly related to the total count. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8214285714285714: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1043.66it/s]\n",
            "Training step 3. Epoch 0: : 3it [07:29, 149.70s/it]\n",
            "Accuracy: 0.4819277108433735: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:34<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.4819277108433735\n",
            "previous_performance:  0.8313253012048193\n",
            "rejected prompt: Answer a reasoning question that involves counting items in a list. Focus on counting only the items relevant to the question. Directly provide the total count without listing each item. Ensure the final line contains only the answer in the format 'Answer: $VALUE' where VALUE is a numerical value. Double-check your count for accuracy before providing the final number. If you encounter any ambiguous items or quantities, make a note of them and proceed with the calculation based on the clear items.\n",
            "sys prompt:  You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of the question and focus on counting the items accurately. List each item you count and then verify the total number. Avoid adding any extra information or context that is not directly related to the total count. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8214285714285714: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1660.49it/s]\n",
            "Accuracy: 0.3132530120481928: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:16<00:00,  5.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.3132530120481928\n",
            "previous_performance:  0.8313253012048193\n",
            "rejected prompt: You will answer a reasoning question that involves counting items in a list. Ensure you understand the context of the question, such as identifying specific categories of items (e.g., vegetables) before counting. Count the items and provide the total number. Be cautious of items that might be similar or easily confused, and ensure you are counting the correct items based on the context. If the query is ambiguous or could be interpreted in multiple ways, provide a brief explanation of your reasoning or ask for clarification. Ensure the response is a single numerical value without any additional text or formatting.\n",
            "sys prompt:  You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of the question and focus on counting the items accurately. List each item you count and then verify the total number. Avoid adding any extra information or context that is not directly related to the total count. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8214285714285714: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1674.21it/s]\n",
            "Accuracy: 0.891566265060241: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [01:00<00:00,  1.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.891566265060241\n",
            "previous_performance:  0.8313253012048193\n",
            "sys prompt:  You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of each item and its relevance to the total count. Use bullet points or numbering with periods for listing items. Maintain consistent naming conventions for similar items (e.g., Bed 1, Bed 2). If there is any ambiguity, provide reasoning for your choice or ask a clarifying question. After listing the items, verify the total count to ensure accuracy. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8571428571428571: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [01:00<00:00,  1.38it/s]\n",
            "Accuracy: 0.8313253012048193: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:43<00:00,  1.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.8313253012048193\n",
            "previous_performance:  0.891566265060241\n",
            "rejected prompt: You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of each item and its relevance to the total count. Use bullet points with a hyphen (-) for each item. Maintain consistent naming conventions for similar items (e.g., Bed 1, Bed 2). If there is any ambiguity, provide reasoning for your choice or ask a clarifying question. After listing the items, state the total number of items in the format: 'The total number of items listed is X.' Ensure the final line contains only the answer in the required format: 'Answer: $VALUE' where VALUE is a numerical value. Double-check your arithmetic to ensure the sum of the counts is correct.\n",
            "sys prompt:  You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of each item and its relevance to the total count. Use bullet points or numbering with periods for listing items. Maintain consistent naming conventions for similar items (e.g., Bed 1, Bed 2). If there is any ambiguity, provide reasoning for your choice or ask a clarifying question. After listing the items, verify the total count to ensure accuracy. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8571428571428571: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1432.86it/s]\n",
            "Training step 3. Epoch 1: : 3it [08:16, 165.36s/it]\n",
            "Accuracy: 0.6144578313253012: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:18<00:00,  4.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.6144578313253012\n",
            "previous_performance:  0.891566265060241\n",
            "rejected prompt: You will answer a reasoning question that involves counting items in a list. Provide only the final count of items without listing intermediate steps. Ensure you understand the context of each item and its relevance to the total count. If there is any ambiguity, ask a clarifying question. Present the numerical value clearly and directly, without any surrounding text or context. Ensure the final answer is a single numerical value without any additional text. Do not repeat the final answer; provide it only once in the specified format. Avoid using ellipses, parentheses, or any other punctuation that could complicate the response. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n",
            "sys prompt:  You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of each item and its relevance to the total count. Use bullet points or numbering with periods for listing items. Maintain consistent naming conventions for similar items (e.g., Bed 1, Bed 2). If there is any ambiguity, provide reasoning for your choice or ask a clarifying question. After listing the items, verify the total count to ensure accuracy. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8571428571428571: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1608.54it/s]\n",
            "Accuracy: 0.5301204819277109: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:16<00:00,  5.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.5301204819277109\n",
            "previous_performance:  0.891566265060241\n",
            "rejected prompt: Count the items and provide the total number as a single integer. Do not include any additional text, explanations, or lists in your response. Ensure the answer is a numerical value only.\n",
            "sys prompt:  You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of each item and its relevance to the total count. Use bullet points or numbering with periods for listing items. Maintain consistent naming conventions for similar items (e.g., Bed 1, Bed 2). If there is any ambiguity, provide reasoning for your choice or ask a clarifying question. After listing the items, verify the total count to ensure accuracy. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8571428571428571: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1517.28it/s]\n",
            "Accuracy: 0.8433734939759037: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [01:20<00:00,  1.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.8433734939759037\n",
            "previous_performance:  0.891566265060241\n",
            "rejected prompt: You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of each item and its relevance to the total count. Use bullet points or numbering with periods for listing items. Maintain consistent naming conventions for similar items (e.g., Bed 1, Bed 2). Ensure that the numbering is sequential and does not skip any numbers. Avoid using ellipses or incomplete names; list each item explicitly. If there is any ambiguity, provide reasoning for your choice or ask a clarifying question. Ensure that each item listed is distinct and not a duplicate. After listing the items, count them explicitly and verify that the total matches the number of distinct items listed. Explicitly show all mathematical operations in your reasoning. For example, if you are adding quantities, write out the full addition process. Before providing the final answer, double-check that the total count is accurate and matches the items listed. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n",
            "sys prompt:  You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of each item and its relevance to the total count. Use bullet points or numbering with periods for listing items. Maintain consistent naming conventions for similar items (e.g., Bed 1, Bed 2). If there is any ambiguity, provide reasoning for your choice or ask a clarifying question. After listing the items, verify the total count to ensure accuracy. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8571428571428571: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1705.01it/s]\n",
            "Accuracy: 0.7710843373493976: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:27<00:00,  3.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_performance:  0.7710843373493976\n",
            "previous_performance:  0.891566265060241\n",
            "rejected prompt: You will answer a reasoning question that involves counting items in a list. Provide a concise answer without detailed explanations. List each item clearly and sequentially without using bullet points or numbering. Use consistent naming conventions for similar items (e.g., Bed 1, Bed 2). If there is any ambiguity, make a reasonable assumption and provide the answer directly. Ensure the final line contains only the answer in the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n",
            "sys prompt:  You will answer a reasoning question that involves counting items in a list. Think step by step, but provide a concise summary of your reasoning. Ensure you understand the context of each item and its relevance to the total count. Use bullet points or numbering with periods for listing items. Maintain consistent naming conventions for similar items (e.g., Bed 1, Bed 2). If there is any ambiguity, provide reasoning for your choice or ask a clarifying question. After listing the items, verify the total count to ensure accuracy. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value. Ensure the final line contains only the answer in the required format.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8571428571428571: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1062.32it/s]\n",
            "Training step 3. Epoch 2: : 3it [07:08, 142.76s/it]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "    for steps, (batch_x, batch_y) in enumerate((pbar := tqdm(train_loader, position=0))):\n",
        "        pbar.set_description(f\"Training step {steps}. Epoch {epoch}\")\n",
        "        optimizer.zero_grad()\n",
        "        losses = []\n",
        "        for (x, y) in zip(batch_x, batch_y):\n",
        "            x = tg.Variable(x, requires_grad=False, role_description=\"query to the language model\")\n",
        "            y = tg.Variable(y, requires_grad=False, role_description=\"correct answer for the query\")\n",
        "            response = model(x)\n",
        "            try:\n",
        "                eval_output_variable = eval_fn(inputs=dict(prediction=response, ground_truth_answer=y))\n",
        "            except:\n",
        "                eval_output_variable = eval_fn([x, y, response])\n",
        "            losses.append(eval_output_variable)\n",
        "        total_loss = tg.sum(losses)\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        run_validation_revert(system_prompt, results, model, eval_fn, val_set)\n",
        "\n",
        "        print(\"sys prompt: \", system_prompt)\n",
        "        test_acc = eval_dataset(test_set, eval_fn, model)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "        results[\"prompt\"].append(system_prompt.get_value())\n",
        "        if steps == 3:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dab7a53-e682-478e-9417-15009b495979",
      "metadata": {
        "id": "7dab7a53-e682-478e-9417-15009b495979"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}